"""
In-Memory Pipeline for Akasa Data Engineering Pipeline.
Processes data using pandas and calculates KPIs without database operations.
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, Optional, List
from pathlib import Path
import json
import sys

# Add paths for imports
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.data_processing.data_cleaner import DataCleaner
from src.kpi_calculators.repeat_customers import RepeatCustomersCalculator
from src.kpi_calculators.monthly_trends import MonthlyTrendsCalculator
from src.kpi_calculators.regional_revenue import RegionalRevenueCalculator
from src.kpi_calculators.top_customers import TopCustomersCalculator
from src.common.logger import setup_logger

logger = setup_logger(__name__)


class NumpyEncoder(json.JSONEncoder):
    """Custom JSON encoder for numpy and pandas data types."""
    
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, pd.Timestamp):
            return obj.isoformat()
        elif pd.isna(obj):
            return None
        return super(NumpyEncoder, self).default(obj)


class InMemoryPipeline:
    """
    In-memory data processing pipeline using pandas operations.
    Processes CSV/XML data and calculates KPIs without database dependencies.
    """
    
    def __init__(self):
        """Initialize the pipeline."""
        self.data_cleaner = DataCleaner()
        self.customers_df: Optional[pd.DataFrame] = None
        self.orders_df: Optional[pd.DataFrame] = None
        self.kpi_results: Dict[str, Any] = {}
        
        logger.info("In-memory pipeline initialized")
    
    def load_data(self, customers_file: str, orders_file: str) -> bool:
        """
        Load and process data from files.
        
        Args:
            customers_file: Path to customers CSV file
            orders_file: Path to orders XML file
            
        Returns:
            True if successful, False otherwise
        """
        try:
            logger.info(f"Loading data from files: {customers_file}, {orders_file}")
            
            # Process customer data
            if not self.data_cleaner.process_customer_data(customers_file):
                logger.error("Failed to process customer data")
                return False
            
            # Process order data
            if not self.data_cleaner.process_order_data(orders_file):
                logger.error("Failed to process order data")
                return False
            
            # Get processed DataFrames
            self.customers_df = self.data_cleaner.get_customers_dataframe()
            self.orders_df = self.data_cleaner.get_orders_dataframe()
            
            if self.customers_df is None or self.orders_df is None:
                logger.error("Failed to get processed data")
                return False
            
            logger.info(f"Data loaded successfully: {len(self.customers_df)} customers, {len(self.orders_df)} orders")
            return True
            
        except Exception as e:
            logger.error(f"Data loading failed: {str(e)}")
            return False
    
    def calculate_all_kpis(self, top_customers_count: int = 10, top_spenders_days: int = 30) -> Dict[str, Any]:
        """
        Calculate all KPIs using in-memory operations.
        
        Args:
            top_customers_count: Number of top customers to return
            top_spenders_days: Number of days for top spenders analysis
            
        Returns:
            Dictionary containing all KPI results
        """
        try:
            if self.customers_df is None or self.orders_df is None:
                logger.error("Data not loaded. Call load_data() first.")
                return {}
            
            logger.info("Starting KPI calculations...")
            
            kpi_results = {}
            
            # 1. Repeat Customers KPI
            logger.info("Calculating repeat customers KPI...")
            repeat_calc = RepeatCustomersCalculator(self.customers_df, self.orders_df)
            kpi_results['repeat_customers'] = repeat_calc.calculate()
            
            # 2. Monthly Trends KPI
            logger.info("Calculating monthly trends KPI...")
            monthly_calc = MonthlyTrendsCalculator(self.customers_df, self.orders_df)
            kpi_results['monthly_trends'] = monthly_calc.calculate()
            
            # 3. Regional Revenue KPI
            logger.info("Calculating regional revenue KPI...")
            regional_calc = RegionalRevenueCalculator(self.customers_df, self.orders_df)
            kpi_results['regional_revenue'] = regional_calc.calculate()
            
            # 4. Top Customers KPI
            logger.info(f"Calculating top customers KPI (last {top_spenders_days} days)...")
            top_calc = TopCustomersCalculator(self.customers_df, self.orders_df, days=top_spenders_days)
            kpi_results['top_customers'] = top_calc.calculate(top_n=top_customers_count)
            
            # Add pipeline metadata
            kpi_results['pipeline_info'] = {
                'pipeline_type': 'in_memory',
                'calculation_date': pd.Timestamp.now().isoformat(),
                'data_summary': {
                    'total_customers': len(self.customers_df),
                    'total_orders': len(self.orders_df),
                    'total_revenue': float(self.orders_df['total_amount'].sum()),
                    'date_range': {
                        'start': self.orders_df['order_date_time'].min().isoformat(),
                        'end': self.orders_df['order_date_time'].max().isoformat()
                    }
                },
                'parameters': {
                    'top_customers_count': top_customers_count,
                    'top_spenders_days': top_spenders_days
                }
            }
            
            self.kpi_results = kpi_results
            
            # Log summary
            self._log_kpi_summary()
            
            logger.info("All KPI calculations completed successfully")
            return kpi_results
            
        except Exception as e:
            logger.error(f"KPI calculation failed: {str(e)}")
            return {}
    
    def _log_kpi_summary(self):
        """Log summary of KPI results."""
        try:
            if not self.kpi_results:
                return
            
            logger.info("=== KPI CALCULATION SUMMARY ===")
            
            # Repeat Customers
            repeat_data = self.kpi_results.get('repeat_customers', {})
            repeat_count = len(repeat_data.get('repeat_customers_list', []))
            single_count = repeat_data.get('single_order_customers', 0)
            logger.info(f"  Repeat Customers: {repeat_count}")
            logger.info(f"  Single Order Customers: {single_count}")
            
            # Monthly Trends
            trends_data = self.kpi_results.get('monthly_trends', {})
            months_analyzed = trends_data.get('total_months', 0)
            logger.info(f"  Monthly Trends: {months_analyzed} months analyzed")
            
            # Regional Revenue
            regional_data = self.kpi_results.get('regional_revenue', {})
            regions_count = regional_data.get('total_regions', 0)
            logger.info(f"  Regional Revenue: {regions_count} regions analyzed")
            
            # Top Customers
            top_data = self.kpi_results.get('top_customers', {})
            top_count = len(top_data.get('top_customers', []))
            period_info = top_data.get('time_period_info', {})
            days = period_info.get('days_analyzed', 0)
            logger.info(f"  Top Customers: {top_count} customers (last {days} days)")
            
            # Overall metrics
            pipeline_info = self.kpi_results.get('pipeline_info', {})
            data_summary = pipeline_info.get('data_summary', {})
            logger.info(f"  Total Revenue: â‚¹{data_summary.get('total_revenue', 0):,.2f}")
            logger.info(f"  Total Customers: {data_summary.get('total_customers', 0)}")
            logger.info(f"  Total Orders: {data_summary.get('total_orders', 0)}")
            
            logger.info("=== END SUMMARY ===")
            
        except Exception as e:
            logger.error(f"Failed to log KPI summary: {str(e)}")
    
    def export_results(self, output_dir: str = "data/outputs/memory_pipeline") -> Dict[str, str]:
        """
        Export KPI results to files.
        
        Args:
            output_dir: Directory to save results
            
        Returns:
            Dictionary with file paths of exported results
        """
        try:
            if not self.kpi_results:
                logger.warning("No KPI results to export. Run calculate_all_kpis() first.")
                return {}
            
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            exported_files = {}
            
            # Export complete KPI results
            complete_results_file = output_path / "in_memory_kpi_results.json"
            with open(complete_results_file, 'w', encoding='utf-8') as f:
                json.dump(self.kpi_results, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)
            exported_files['complete_results'] = str(complete_results_file)
            
            # Export individual KPI results
            for kpi_name, kpi_data in self.kpi_results.items():
                if kpi_name != 'pipeline_info':
                    kpi_file = output_path / f"kpi_{kpi_name}.json"
                    with open(kpi_file, 'w', encoding='utf-8') as f:
                        json.dump(kpi_data, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)
                    exported_files[kpi_name] = str(kpi_file)
            
            # Export summary report
            summary_report = self._generate_summary_report()
            summary_file = output_path / "in_memory_pipeline_summary.json"
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_report, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)
            exported_files['summary_report'] = str(summary_file)
            
            # Export data quality report
            data_quality_report = self._generate_data_quality_report()
            quality_file = output_path / "data_quality_report.json"
            with open(quality_file, 'w', encoding='utf-8') as f:
                json.dump(data_quality_report, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)
            exported_files['data_quality'] = str(quality_file)
            
            # Create visualizations and CSV exports
            try:
                sys.path.append(str(Path(__file__).parent.parent))
                from visualization.visualizer import create_pipeline_visualizations
                viz_files = create_pipeline_visualizations(
                    pipeline_type="memory", 
                    kpi_data=self.kpi_results,
                    output_dir=str(output_path.parent.parent)  # data/outputs
                )
                exported_files.update(viz_files)
                logger.info(f"Created {len(viz_files)} visualization and CSV files")
            except Exception as viz_error:
                logger.warning(f"Visualization creation failed: {viz_error}")
            
            logger.info(f"Results exported to {len(exported_files)} files in {output_dir}")
            return exported_files
            
        except Exception as e:
            logger.error(f"Results export failed: {str(e)}")
            return {}
    
    def _generate_summary_report(self) -> Dict[str, Any]:
        """Generate a comprehensive summary report."""
        try:
            if not self.kpi_results:
                return {}
            
            pipeline_info = self.kpi_results.get('pipeline_info', {})
            data_summary = pipeline_info.get('data_summary', {})
            
            # Extract key metrics from each KPI
            repeat_customers = self.kpi_results.get('repeat_customers', {})
            monthly_trends = self.kpi_results.get('monthly_trends', {})
            regional_revenue = self.kpi_results.get('regional_revenue', {})
            top_customers = self.kpi_results.get('top_customers', {})
            
            return {
                'pipeline_summary': {
                    'pipeline_type': 'In-Memory (Pandas)',
                    'calculation_date': pipeline_info.get('calculation_date'),
                    'processing_status': 'SUCCESS',
                    'data_processed': {
                        'customers': data_summary.get('total_customers', 0),
                        'orders': data_summary.get('total_orders', 0),
                        'revenue': data_summary.get('total_revenue', 0)
                    }
                },
                'key_insights': {
                    'customer_retention': {
                        'repeat_customers': len(repeat_customers.get('repeat_customers_list', [])),
                        'retention_rate': repeat_customers.get('retention_metrics', {}).get('retention_rate_pct', 0)
                    },
                    'business_growth': {
                        'months_analyzed': monthly_trends.get('total_months', 0),
                        'growth_trend': monthly_trends.get('growth_metrics', {}).get('revenue_trend_direction', 'unknown')
                    },
                    'market_distribution': {
                        'regions_covered': regional_revenue.get('total_regions', 0),
                        'top_region': regional_revenue.get('top_regions', {}).get('by_revenue', [{}])[0].get('region', 'N/A') if regional_revenue.get('top_regions', {}).get('by_revenue') else 'N/A'
                    },
                    'customer_value': {
                        'vip_customers': len([c for c in top_customers.get('customer_segments', {}).get('segments', []) if c.get('segment') == 'VIP']),
                        'high_value_threshold': top_customers.get('customer_segments', {}).get('segment_thresholds', {}).get('vip_threshold', 0)
                    }
                },
                'performance_metrics': {
                    'processing_efficiency': 'High (In-Memory Operations)',
                    'data_completeness': '100%',
                    'calculation_accuracy': 'High (Pandas Precision)'
                }
            }
            
        except Exception as e:
            logger.error(f"Summary report generation failed: {str(e)}")
            return {}
    
    def _generate_data_quality_report(self) -> Dict[str, Any]:
        """Generate data quality assessment report."""
        try:
            if self.customers_df is None or self.orders_df is None:
                return {}
            
            # Customer data quality
            customer_quality = {
                'total_records': len(self.customers_df),
                'duplicate_mobile_numbers': self.customers_df['mobile_number'].duplicated().sum(),
                'missing_names': self.customers_df['customer_name'].isnull().sum(),
                'missing_regions': self.customers_df['region'].isnull().sum(),
                'unique_regions': self.customers_df['region'].nunique(),
                'region_distribution': self.customers_df['region'].value_counts().to_dict()
            }
            
            # Order data quality
            order_quality = {
                'total_records': len(self.orders_df),
                'duplicate_order_ids': self.orders_df['order_id'].duplicated().sum(),
                'missing_amounts': self.orders_df['total_amount'].isnull().sum(),
                'zero_amounts': (self.orders_df['total_amount'] == 0).sum(),
                'negative_amounts': (self.orders_df['total_amount'] < 0).sum(),
                'missing_dates': self.orders_df['order_date_time'].isnull().sum(),
                'date_range': {
                    'earliest': self.orders_df['order_date_time'].min().isoformat(),
                    'latest': self.orders_df['order_date_time'].max().isoformat()
                },
                'amount_statistics': {
                    'min': float(self.orders_df['total_amount'].min()),
                    'max': float(self.orders_df['total_amount'].max()),
                    'mean': float(self.orders_df['total_amount'].mean()),
                    'median': float(self.orders_df['total_amount'].median())
                }
            }
            
            # Data relationship quality
            customer_mobiles = set(self.customers_df['mobile_number'])
            order_mobiles = set(self.orders_df['mobile_number'])
            
            relationship_quality = {
                'orders_without_customers': len(order_mobiles - customer_mobiles),
                'customers_without_orders': len(customer_mobiles - order_mobiles),
                'data_integrity_score': (
                    len(order_mobiles & customer_mobiles) / len(order_mobiles | customer_mobiles) * 100
                ) if order_mobiles | customer_mobiles else 0
            }
            
            return {
                'assessment_date': pd.Timestamp.now().isoformat(),
                'customer_data_quality': customer_quality,
                'order_data_quality': order_quality,
                'relationship_quality': relationship_quality,
                'overall_score': self._calculate_quality_score(customer_quality, order_quality, relationship_quality)
            }
            
        except Exception as e:
            logger.error(f"Data quality report generation failed: {str(e)}")
            return {}
    
    def _calculate_quality_score(self, customer_quality: Dict, order_quality: Dict, relationship_quality: Dict) -> Dict[str, Any]:
        """Calculate overall data quality score."""
        try:
            # Simple scoring system (0-100)
            score = 100
            
            # Deduct for data issues
            if customer_quality.get('duplicate_mobile_numbers', 0) > 0:
                score -= 10
            if customer_quality.get('missing_names', 0) > 0:
                score -= 5
            if order_quality.get('duplicate_order_ids', 0) > 0:
                score -= 10
            if order_quality.get('zero_amounts', 0) > 0:
                score -= 5
            if order_quality.get('negative_amounts', 0) > 0:
                score -= 10
            if relationship_quality.get('data_integrity_score', 100) < 95:
                score -= 15
            
            # Determine grade
            if score >= 95:
                grade = 'Excellent'
            elif score >= 85:
                grade = 'Good'
            elif score >= 70:
                grade = 'Fair'
            else:
                grade = 'Poor'
            
            return {
                'score': max(0, score),
                'grade': grade,
                'recommendations': self._get_quality_recommendations(customer_quality, order_quality, relationship_quality)
            }
            
        except Exception as e:
            logger.error(f"Quality score calculation failed: {str(e)}")
            return {'score': 0, 'grade': 'Unknown', 'recommendations': []}
    
    def _get_quality_recommendations(self, customer_quality: Dict, order_quality: Dict, relationship_quality: Dict) -> List[str]:
        """Generate data quality improvement recommendations."""
        recommendations = []
        
        if customer_quality.get('duplicate_mobile_numbers', 0) > 0:
            recommendations.append("Remove or consolidate duplicate customer mobile numbers")
        
        if order_quality.get('duplicate_order_ids', 0) > 0:
            recommendations.append("Investigate and resolve duplicate order IDs")
        
        if order_quality.get('negative_amounts', 0) > 0:
            recommendations.append("Review and correct negative order amounts")
        
        if relationship_quality.get('orders_without_customers', 0) > 0:
            recommendations.append("Add customer records for orders with missing customer data")
        
        if relationship_quality.get('data_integrity_score', 100) < 95:
            recommendations.append("Improve data linking between customers and orders")
        
        return recommendations
    
    def get_kpi_results(self) -> Dict[str, Any]:
        """Get calculated KPI results."""
        return self.kpi_results.copy()
    
    def get_data_summary(self) -> Dict[str, Any]:
        """Get summary of loaded data."""
        if self.customers_df is None or self.orders_df is None:
            return {}
        
        return {
            'customers': {
                'total_count': len(self.customers_df),
                'by_region': self.customers_df['region'].value_counts().to_dict()
            },
            'orders': {
                'total_count': len(self.orders_df),
                'total_revenue': float(self.orders_df['total_amount'].sum()),
                'avg_order_value': float(self.orders_df['total_amount'].mean()),
                'date_range': {
                    'start': self.orders_df['order_date_time'].min().isoformat(),
                    'end': self.orders_df['order_date_time'].max().isoformat()
                }
            }
        }
